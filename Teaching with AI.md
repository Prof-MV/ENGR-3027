# Teaching with AI

## Summary of the [Anthropic Economic Index Report](https://www.anthropic.com/research/anthropic-economic-index-january-2026-report)

This comprehensive report analyzes how AI (specifically Claude) is being used in the economy and what it reveals about AI's impact on work and productivity. Here are the key findings:

### Main Findings:

**1. AI Usage Patterns:**

- Claude is predominantly used for **coding and technical work** (34% of consumer use)
- The top 10 tasks account for 24% of all usage, showing high concentration
- Usage varies by income level: higher-income countries use AI for work and personal tasks, while lower-income countries use it more for coursework

**2. Complex Tasks Show Greater Benefits:**

- More complex, higher-education tasks see **12x speedups** compared to 9x for simpler tasks
- However, complex tasks have **lower success rates** (61-66% vs. 70%)
- AI tends to be used for tasks requiring more education than the broader economy average

**3. Geographic Patterns:**

- US states are converging in adoption (could reach parity in 2-5 years)
- Global adoption remains uneven, strongly correlated with GDP per capita
- States with more tech workers show higher AI adoption

**4. Productivity Impact:**

- Initial estimate: AI could boost labor productivity by **1.8 percentage points annually** over the next decade
- When adjusted for task success rates: drops to **1.0-1.2 percentage points**
- If tasks are complementary (bottleneck effects): could be as low as 0.6-0.8 percentage points

**5. Job Impact Patterns:**

- 49% of jobs have AI usage for at least 25% of their tasks
- AI tends to automate the **more skilled tasks** within jobs, leaving less-skilled work behind
- Some jobs will experience "deskilling" (travel agents, technical writers), others "upskilling" (real estate managers)

---

## How This Should Change Teaching:

### 1. **Shift Focus from Task Completion to Task Design**

The report shows AI excels at completing well-defined tasks but requires sophisticated human prompts. Teaching should emphasize:

- How to break complex problems into AI-manageable tasks
- How to write effective prompts and iterate on AI responses
- Critical evaluation of AI outputs rather than just executing tasks

### 2. **Emphasize Higher-Order Skills**

Since AI handles routine cognitive work effectively, education must prioritize:

- **Critical thinking and validation** - The report shows AI success rates drop on complex tasks; students need to verify and improve AI output
- **Creative problem-framing** - Defining what problems to solve, not just how to solve them
- **Synthesis and judgment** - Combining AI-generated components into coherent wholes

### 3. **Teach AI Collaboration, Not Just AI Use**

The report distinguishes between "automation" (delegating tasks) and "augmentation" (iterating with AI). Students need:

- Experience with multi-turn AI conversations for complex projects
- Skills in refining and improving AI responses through iteration
- Understanding when to delegate vs. when to collaborate

### 4. **Address the Education Paradox**

The report finds a nearly perfect correlation between prompt sophistication and response quality. This means:

- **Writing and communication skills** become even more critical
- Students need strong foundational knowledge to get quality AI assistance
- "AI will do it for me" is a trap - you need expertise to use AI effectively

### 5. **Focus on Bottleneck and Complementary Skills**

Since AI creates productivity bottlenecks at tasks it can't automate:

- Teach skills AI struggles with: hands-on work, in-person interaction, complex judgment
- Emphasize tasks requiring **contextual understanding** and **ethical reasoning**
- Build skills in areas where human judgment remains essential (the report shows lower success on most complex tasks)

### 6. **Prepare for Job Transformation, Not Job Elimination**

The report shows jobs won't disappear but will change:

- Teach students to identify which parts of their future jobs will be AI-assisted
- Develop adaptability and continuous learning skills
- Focus on the "human-in-the-loop" skills that complement AI automation

### 7. **Bridge the Global AI Skills Gap**

The report reveals that **lower-income regions use AI primarily for coursework**, suggesting an opportunity:

- Explicitly teach AI literacy as a foundational skill
- Ensure all students can access and effectively use AI tools
- Address equity concerns - the report shows usage correlates with income and education

### 8. **Rethink Assessment Methods**

Since AI can complete most traditional assignments:

- Move toward **process-based assessment** (how students work with AI)
- Emphasize **in-class demonstrations** of understanding
- Value iteration and refinement over first-draft perfection
- Test application and synthesis, not just knowledge recall

### Bottom Line:

Education must shift from teaching students to complete tasks independently to teaching them to **work effectively alongside AI** while developing the judgment, creativity, and critical thinking that AI still struggles with. The goal is preparing students for a world where AI handles routine cognitive work while humans provide direction, validation, and higher-order thinking.

Lesson Plan:

# Lesson Plan: Effective Use of AI in Electromechanical Engineering

## Lesson Overview

- **Title**: Integrating AI Tools for Enhanced Productivity in Electromechanical Engineering
- **Target Audience**: Undergraduate or graduate electromechanical engineering students, primarily preparing for careers in automotive, food processing, defense, and mining industries.
- **Duration**: 3 hours (can be split into two 1.5-hour sessions)
- **Objectives**:
    - Understand AI's role in technical work, based on key findings from the Anthropic Economic Index Report (e.g., AI's strengths in coding and complex tasks, but lower success rates for high-complexity work).
    - Develop skills in prompt engineering, iterative AI collaboration, and critical evaluation of AI outputs.
    - Apply AI to industry-specific tasks in automotive, food, defense, and mining, emphasizing augmentation over automation.
    - Foster higher-order skills like problem-framing, synthesis, and ethical reasoning to address AI's limitations and productivity bottlenecks.
- **Materials Needed**:
    - Access to AI tools (e.g., Claude, ChatGPT, or similar).
    - Laptops or computers for hands-on exercises.
    - Projector for demonstrations.
    - Handouts: Summary of the Anthropic Report and prompt engineering rules.
    - Attached document for reference (provided in the query).

## Introduction (20 minutes)

- **Hook**: Begin with a discussion on AI's impact on engineering jobs. Share key report findings: AI boosts productivity by 1.0-1.2 percentage points annually when adjusted for success rates, but it automates skilled tasks more than routine ones, leading to job transformation (e.g., deskilling in technical writing vs. upskilling in management roles).
- **Overview of AI in Engineering**: Explain how AI is used for 34% of consumer tasks in coding/technical work. In industries like automotive (e.g., simulation modeling), food (e.g., process optimization), defense (e.g., system design), and mining (e.g., equipment diagnostics), AI excels at complex tasks with 12x speedups but has 61-66% success rates, requiring human oversight.
- **Relevance to Teaching**: Highlight the "education paradox" – strong foundational knowledge is needed to use AI effectively. Shift focus from independent task completion to AI collaboration, as per the report's recommendations.

## Main Content and Activities

### Section 1: Understanding AI Usage Patterns and Limitations (30 minutes)

- **Lecture/Discussion**: Review report insights on geographic and task-based patterns. Discuss how higher-income regions (like those with automotive/defense hubs) use AI for work, while others focus on coursework. Emphasize that AI handles tasks requiring more education but creates bottlenecks in hands-on or contextual work (e.g., ethical decisions in defense systems).
- **Activity**: Group brainstorm (10 minutes) – Students identify AI-applicable tasks in their industries:
    - Automotive: Simulating electromechanical systems for electric vehicles.
    - Food: Optimizing conveyor belt designs for processing lines.
    - Defense: Modeling drone propulsion systems.
    - Mining: Predictive maintenance for drilling equipment.
- **Key Takeaway**: AI augments productivity but requires human judgment for complex, low-success tasks.

### Section 2: Prompt Engineering Rules and Examples (40 minutes)

- **Lecture**: Teach rules for best prompt engineering, drawing from the report's emphasis on prompt sophistication correlating with response quality. Rules include:
    1. **Be Specific and Structured**: Provide clear context, constraints, and desired output format.
    2. **Use Role-Playing**: Assign the AI a persona (e.g., "Act as an experienced automotive engineer").
    3. **Break Down Tasks**: Decompose complex problems into steps to leverage AI's strengths in well-defined tasks.
    4. **Include Examples**: Provide sample inputs/outputs to guide AI.
    5. **Specify Iteration**: Ask for step-by-step reasoning or alternatives.
    6. **Avoid Ambiguity**: Use precise language; define terms if needed.
    7. **Ethical Guardrails**: Include instructions to consider safety, regulations, and biases (e.g., in defense applications).
- **Example Prompts** (Tailored to Industries):
    - **Automotive**: "Act as a senior electromechanical engineer specializing in electric vehicles. Design a basic control system for a regenerative braking mechanism. Include: 1) Key components (motors, sensors), 2) Energy flow diagram, 3) Potential failure modes, and 4) Compliance with ISO 26262 safety standards. Output in markdown with bullet points and a simple pseudocode snippet."
    - **Food Processing**: "You are a food industry consultant. Optimize an electromechanical mixer for high-viscosity dough in a bakery line. Specify: motor torque requirements, speed control algorithms, hygiene considerations (e.g., IP67 rating), and energy efficiency calculations. Provide a step-by-step breakdown and suggest two alternative designs."
    - **Defense**: "As a defense systems expert, simulate the electromechanical integration for a missile guidance system. Detail: actuators, feedback loops, power requirements, and redundancy for fault tolerance. Ensure considerations for MIL-STD-810 environmental testing. Output as a numbered list with pros/cons."
    - **Mining**: "Pretend you're a mining equipment engineer. Troubleshoot vibration issues in a conveyor belt system for ore transport. Include: diagnostic steps, sensor recommendations, AI-based predictive models, and safety protocols per MSHA regulations. Format as a troubleshooting flowchart in text."
- **Hands-On Exercise**: Students practice rewriting vague prompts (e.g., "Help with car brakes") into effective ones using the rules. Share and critique in pairs.

### Section 3: Iterative AI Collaboration and Higher-Order Skills (50 minutes)

- **Lecture**: Based on the report's distinction between automation and augmentation, teach multi-turn interactions. AI succeeds more with iteration, especially for complex tasks. Emphasize critical thinking: validate outputs, synthesize results, and apply judgment where AI falls short (e.g., ethical or contextual issues).
- **Examples of Iterative Approach**:
    - **Initial Prompt (Automotive Example)**: "Describe a basic electromechanical system for an autonomous vehicle's steering."
        - AI Response: Generic overview (e.g., motors, sensors).
    - **Iteration 1**: "Expand on your previous response: Add calculations for torque needed for a 2000kg vehicle at 60km/h turns. Include safety factors."
        - AI Response: Adds math but misses edge cases.
    - **Iteration 2**: "Review the torque calculations – assume wet road conditions and recalculate. Suggest improvements for energy efficiency and cite any automotive standards."
        - AI Response: Refined with specifics; student evaluates for accuracy.
    - **Final Synthesis**: Student combines iterations, adds human insight (e.g., "Incorporate haptic feedback for driver override, as AI may not handle all ethical dilemmas in defense scenarios").
    - **Food Example Iteration**: Start with "Design a pump for liquid food transfer." Iterate: "Incorporate FDA compliance," then "Optimize for variable viscosity," ending with student validation of hygienic design.
- **Activity**: In small groups, students engage in a multi-turn AI session for an assigned task (e.g., mining equipment diagnostics). Document iterations and discuss bottlenecks (e.g., AI's lower success on complex judgments like site-specific geology).

### Section 4: Example Research Topics and Application (30 minutes)

- **Lecture**: Encourage research that bridges AI gaps, focusing on complementary skills like hands-on work and ethical reasoning. Tie to job transformation: Prepare for "human-in-the-loop" roles.
- **Example Research Topics** (Industry-Specific, Promoting Critical Thinking):
    - **Automotive**: "Evaluate AI-generated designs for hybrid engine electromechanical interfaces: Compare simulation accuracy to real-world testing data, focusing on bottlenecks in high-speed scenarios."
    - **Food**: "Investigate AI-optimized sorting machines: Analyze success rates for delicate produce handling and propose human-AI hybrid protocols for quality control."
    - **Defense**: "Assess AI in electromechanical targeting systems: Research ethical implications of automation in urban environments and develop guidelines for human oversight."
    - **Mining**: "Use AI to model drill bit wear: Study productivity impacts, incorporating field data from varied terrains to address AI's lower success in complex geological tasks."
- **Activity**: Assign students to select a topic, generate an initial AI prompt, and outline an iterative research plan. Discuss equity (e.g., ensuring AI access in lower-income mining regions).

## Assessment (10 minutes)

- **Formative**: Observe participation in activities; collect prompt examples and iteration logs for feedback.
- **Summative**: Short quiz on report key findings and prompt rules. Assign a take-home project: Develop an AI-assisted electromechanical design proposal for one industry, including iterations and critical evaluation (process-based assessment, as recommended in the report).
- **Rubric Focus**: Emphasis on prompt quality, iteration evidence, output validation, and higher-order synthesis (not just final product).

## Conclusion (10 minutes)

- **Recap**: Reiterate the bottom line from the report – Shift to working alongside AI, developing judgment and creativity. In electromechanical engineering, AI handles routine cognitive tasks, but humans excel in direction, validation, and complex contexts.
- **Q&A**: Address concerns like job impacts or global skills gaps.
- **Next Steps**: Encourage ongoing AI practice and continuous learning for adaptability in transforming industries.

# Automated Evaluation Methods for Large Electromechanical Engineering Classes

Teaching electromechanical engineering to large class sizes, especially with a focus on AI integration as outlined in the "Teaching with AI" summary, presents unique challenges. One-on-one evaluations are indeed resource-intensive, so shifting toward automated or semi-automated methods aligns with the document's recommendation to rethink assessments: emphasize process-based evaluation, in-class demonstrations, iteration, and synthesis over rote recall. Below, I'll suggest ways to incorporate arithmetic, true/false (T/F), and multiple-choice questions (MCQs) where feasible, explain their limitations, and provide alternative ideas drawing from best practices in engineering education.

## Using Arithmetic, True/False, and Multiple-Choice Questions for Automated Evaluation

These question types are well-suited for automation because they can be easily graded via learning management systems (LMS) like Canvas, Moodle, or Blackboard, or tools like Google Forms/Quizzes. They work best for assessing foundational knowledge and basic application, which complements AI's role in handling routine cognitive tasks (per the report). However, they may not fully capture higher-order skills like prompt engineering, critical evaluation of AI outputs, or ethical reasoning in industries like automotive, food, defense, and mining.

### 1. **Arithmetic Questions**

- **How to Use Them**: These are ideal for evaluating computational skills in electromechanical contexts, such as calculations for system design or optimization. They can be auto-graded instantly, providing immediate feedback and reducing instructor workload.
    - **Examples Tailored to Your Industries**:
        - Automotive: "Calculate the torque required for an electric motor in a regenerative braking system for a 1500kg vehicle decelerating from 60km/h to 0km/h in 5 seconds. (Answer: 1800 Nm)"
        - Food Processing: "Determine the power output needed for a conveyor belt motor handling 500kg of product per hour at a speed of 2m/s with a 15% efficiency loss. (Answer: 3.27 kW)"
        - Defense: "Compute the angular velocity of a servo actuator in a missile guidance system given a 2m radius and linear speed of 300m/s. (Answer: 150 rad/s)"
        - Mining: "Calculate the force exerted by a hydraulic cylinder in a drilling rig with a piston area of 0.05m² and pressure of 10MPa. (Answer: 500kN)"
- **Automation Tips**: Use LMS tools with equation editors (e.g., LaTeX support) or integrate with Wolfram Alpha via APIs for verification. Randomize variables to prevent cheating.
- **Alignment with AI Teaching**: Pair with AI prompts—e.g., ask students to use AI to verify their calculations, then answer an arithmetic question on the discrepancy. This assesses iteration without manual grading.
- **Limitations**: Doesn't evaluate creative problem-framing or AI collaboration directly; AI can solve these easily, so focus on in-class timed quizzes to ensure authenticity.

### 2. **True/False Questions**

- **How to Use Them**: Great for quick checks on conceptual understanding and misconceptions, especially in AI ethics or system principles. They auto-grade binary responses efficiently.
    - **Examples**:
        - "True or False: In defense applications, AI can autonomously handle all ethical decisions in electromechanical targeting systems without human oversight." (False—emphasizes human judgment bottlenecks from the report.)
        - "True or False: Prompt sophistication has a nearly perfect correlation with AI response quality in complex engineering tasks." (True—directly from the report.)
        - "True or False: In mining equipment diagnostics, AI excels at predictive maintenance but struggles with site-specific geological contexts." (True.)
- **Automation Tips**: Use question banks with randomization to scale for large classes. Tools like Quizlet or Kahoot! allow real-time group participation.
- **Alignment with AI Teaching**: Follow up with explanations requiring students to justify their answer via AI-generated rationale, but auto-grade only the T/F part.
- **Limitations**: Oversimplifies nuanced topics; can't assess synthesis or iteration.

### 3. **Multiple-Choice Questions**

- **How to Use Them**: Effective for scenario-based application, where options test judgment. Design with distractors based on common AI errors to encourage critical thinking.
    - **Examples**:
        - Automotive: "Which prompt engineering rule best improves AI output for simulating an EV battery management system? A) Be vague for creativity, B) Break down into steps, C) Avoid examples, D) Ignore constraints." (B)
        - Food: "In optimizing a robotic arm for packaging, AI suggests a design with 95% efficiency. The best next step is: A) Accept immediately, B) Iterate with wet-condition simulations, C) Delegate fully to AI, D) Skip validation." (B—tests iteration.)
        - Defense/Mining: "For a drone's electromechanical propulsion in hostile environments, which factor does AI struggle with most per productivity reports? A) Basic calculations, B) Ethical reasoning, C) Routine coding, D) Data entry." (B)
- **Automation Tips**: Use adaptive quizzing in LMS (e.g., harder questions based on prior answers) or AI tools like Gradescope for partial credit on similar responses.
- **Alignment with AI Teaching**: Incorporate questions on AI usage patterns (e.g., from the report's findings on complex task success rates).
- **Limitations**: AI can generate answers, so use proctored or timed settings. Doesn't fully assess process or collaboration.

### Feasibility Assessment

These formats are possible and scalable for large classes, covering 70-80% of foundational evaluations (e.g., knowledge recall and basic application). They align with the report's emphasis on testing synthesis indirectly through well-crafted questions. However, they're insufficient for fully assessing AI collaboration skills, as the report notes AI's lower success on complex tasks requires human validation—something not captured in auto-graded formats. For comprehensive evaluation, blend with alternatives below.

## Alternative Evaluation Methods If Traditional Formats Fall Short

If arithmetic/T/F/MCQs don't suffice for higher-order skills (e.g., prompt design, iteration), consider these semi-automated or AI-assisted methods, which reduce manual effort while promoting the report's goals of process-based assessment and AI augmentation:

1. **AI-Driven Grading Tools**:
    - Use platforms like Gradescope or AssessMate, which employ machine learning to group and grade open-ended responses (e.g., short essays on AI prompts). Instructors review clusters, not individual submissions—ideal for large classes.
    - Example: Students submit AI interaction logs (prompts + outputs) for an electromechanical design task; AI tool scores consistency and sophistication.
2. **Process-Based Submissions with Auto-Checks**:
    - Require multi-turn AI conversation logs (as in the lesson plan's iterative examples). Use scripts or tools to auto-verify elements like iteration count or keyword presence (e.g., "refine" or "validate").
    - For engineering labs: Auto-grade code or simulations via platforms like Jupyter Notebooks with built-in testers.
3. **In-Class Demonstrations with Polling Tools**:
    - Use tools like Mentimeter or Poll Everywhere for real-time, auto-tabulated responses during live AI collaboration demos. Assess understanding via aggregated data.
4. **Peer Review with AI Assistance**:
    - Students review peers' AI-assisted projects anonymously via rubrics; AI tools (e.g., from Gradescope) suggest scores to streamline. This scales feedback without full instructor involvement.
5. **Hybrid AI-Integrated Assessments**:
    - Design tasks where students critique AI-generated designs (e.g., "Improve this AI-outputted mining rig schematic"). Auto-grade multiple-choice follow-ups on their critiques.
6. **Adaptive Online Quizzes and Simulations**:
    - Platforms like Coursera's auto-graded labs or custom simulations in MATLAB/Simulink for electromechanical tasks. Integrate AI to generate personalized questions.

## Implementation Tips for Large Classes

- **Equity Considerations**: As the report notes usage correlates with income, provide AI tool access and training to all students.
- **Prevent Cheating**: Use question randomization, time limits, and plagiarism detectors for AI-generated content.
- **Pilot and Iterate**: Start with a subset of assessments automated, gather feedback, and refine—mirroring the iterative AI approach.
- **Productivity Boost**: These methods can reduce grading time by 50-70%, allowing focus on high-value interactions.

By combining these, you'll prepare students for AI-augmented industries while managing scale effectively. If you share more details on specific course topics, I can refine these further.

# Chapter: Becoming Dangerously Intelligent in the AI Era

Most people are currently letting Artificial Intelligence destroy their ability to think, essentially training the technology to become their own replacement. However, the **top 1% use AI backwards**: they do not simply prompt to get answers, but rather use it to **train their brains** and outsmart any situation. This chapter outlines a comprehensive four-step framework to transition from a passive user to a "dangerously intelligent" practitioner.

---

## Step 1: Intelligent Laziness and the DRAG Framework

The human brain suffers from a biological glitch called **completion bias**, where we seek the immediate dopamine hit of finishing any task, regardless of its value. This leads to **priority blindness**, where we treat formatting a slide the same as a million-dollar strategy document.

### The Two Curves of Effort

To master intelligent laziness, you must distinguish between two types of work:

- **Curve 1 (Capped Payoffs):** Tasks like expense reports or internal emails where value flatlines after a point of "good enough" (satisficing).
- **Curve 2 (Uncapped Payoffs):** Tasks like product design, pricing models, or finding partners. Here, being 1% better can solve 99% of your problems. This is your **zone of obsession**.

### The DRAG Framework for Delegation

Outsource Curve 1 tasks to AI using the **DRAG** framework so you can focus on Curve 2:

- **D – Drafting:** Use AI to solve the "blank page problem." Even a "crappy" first draft provides a starting point to trigger your brain.
- **R – Research:** Use "deep research" features to have AI act as a consultant, firing off hundreds of queries to consolidate results in minutes rather than days.
- **A – Analysis:** Let AI take the first pass at finding patterns in unstructured data that humans might miss.
- **G – Grunt Work:** Delegate repetitive, manual tasks like reformatting, translating, and data cleaning.

**Best Practice:** Use the **AIM protocol** (Act in this role, Input, Mission) when delegating drafting tasks to ensure the AI has clear direction.

---

## Step 2: The Intelligent Hill (Advanced Prompting)

AI is not a calculator (predictable and certain); it is a **probability engine**. To get elite results, you must move beyond "zero-shot prompting" (asking a question with no context) and climb the **Intelligent Hill**:

1. **One-shot Prompting:** Provide one clear example or style guide so the model doesn't guess blindly.
2. **Few-shot Prompting (Grounding):** Provide three or more examples. This "grounds" the model in reality and prevents hallucinations.
    - *Pro Tip:* Ask the AI to explain the pattern back to you first to ensure it understands your tone or logic.
3. **Chain of Thought Reasoning:** Slow the AI down by asking it to **"think step-by-step"** and show its work. This reduces errors and forces explicit clarity.
4. **Agents:** Use agentic prompts that assign multiple roles (e.g., researcher, analyst, and copywriter) to complete complex, multi-stage missions.

---

## Step 3: The Intelligent Gym

While you should remove friction for information tasks, you must **add friction for transformation tasks**. If you use AI as a "wheelchair for the mind," your cognitive abilities will atrophy.

### The "Spotter" Method

Instead of asking AI to do the work, treat it as a **gym spotter** who helps you lift the weight without doing it for you.

- **Study first:** Learn a concept independently.
- **Quiz me:** Ask the AI to test your knowledge.
- **Progressive Overload:** Increase the difficulty of the AI’s questioning through four levels:
    - *Level 1:* High school student.
    - *Level 2:* College student.
    - *Level 3:* Executive job interview.
    - *Level 4:* An irate boss who thinks you are unprepared.

---

## Step 4: The Intelligent Fool

The greatest obstacle to intelligence is ego. To truly grow, you must adopt the **"fool's advantage"**—the willingness to admit what you do not know.

### The "Learn-it-all" Culture

Following the example of Microsoft’s cultural shift under Satya Nadella, move from being a **"know-it-all"** to a **"learn-it-all"**. Neuroplasticity—the brain’s ability to rewire itself—only happens at the edge of your ability when you are making errors and feeling frustrated.

### Implementation:

- **Ask the "Dumb" Questions:** Use AI to ask the basic questions you might be too embarrassed to ask colleagues.
- **Iterative Simplification:** If you don't understand a complex topic, ask AI to "explain it like I'm 10 years old." If it's still unclear, ask it to simplify again and again.

**Main Insight:** True intelligence is not the end of ignorance, but the **end of pretending**. Use AI to peel away the mask of mastery and become a genuine student for life.

[IA9](https://www.notion.so/IA9-2e581199f05481e4b342daa4d557f40c?pvs=21)